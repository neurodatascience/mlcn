{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "## Conceptual questions:\n",
    "### Q2.1\n",
    "Why should we do cross-validation of our models? What is its purpose?  \n",
    "\n",
    "### Q2.2\n",
    "Describe K-fold cross-validation. What is the benefit of having multiple, separate validation sets?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises:\n",
    "## Q2.3\n",
    "Load the Boston housing prices (`sklearn.datasets.load_boston`), and fit a linear regressor. Perform 5-, 10-, and 100-fold cross-validation. Examine the returned performance metrics.  \n",
    "Use ShuffleSplit cross-validation with varying training sizes; does this compare to k-fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import KFold, train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_data, y_labels = load_boston(return_X_y=True)\n",
    "x_data_train, x_data_test, y_labels_train, y_labels_test = train_test_split(x_data, y_labels, train_size=0.8)\n",
    "\n",
    "lrc = LinearRegression()\n",
    "scores_5 = cross_val_score(lrc, x_data_train, y_labels_train, cv=5)\n",
    "scores_10 = cross_val_score(lrc, x_data_train, y_labels_train, cv=10)\n",
    "scores_100 = cross_val_score(lrc, x_data_train, y_labels_train, cv=100)\n",
    "scores_ss = cross_val_score(lrc, x_data_train, y_labels_train, cv=ShuffleSplit(n_splits=100, train_size=0.8))\n",
    "print('5-fold: ' + str(np.mean(scores_5)))\n",
    "print('10-fold: ' + str(np.mean(scores_10)))\n",
    "print('100-fold: ' + str(np.mean(scores_100)))\n",
    "print('ShuffleSplit: ' + str(np.mean(scores_ss)))\n",
    "\n",
    "print(x_data_train.shape)\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,10,5), scores_5,'.-')\n",
    "plt.plot(np.linspace(0,10,10),scores_10,'.-')\n",
    "plt.title('KFold 5 & 10')\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,10,100),scores_100,'.-')\n",
    "plt.title('KFold 100')\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,10,100),scores_ss,'.-')\n",
    "plt.title('ShuffleSplit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- and 10-fold CV are similar. 100-fold CV leaves 4 samples in the validation set, resulting in high variance. ShuffleSplit with a large training size behaves similarly to 100-fold CV. Large values for `n_splits` gives redundant information since the validation sets overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.4\n",
    "Load the digits dataset (`sklearn.datasets.load_digits`). Note that each sample is an 8x8 image flattened to be 64x1. Select a classifier (e.g. logistic regression or support vector machine), and try to classify the digits. How well can you do? Where are the mistakes coming from?\n",
    "\n",
    "Note: If you want to visualize the data, you can use numpy's reshape function:  \n",
    "`from matplotlib import pyplot as plt; import sklearn.datasets\n",
    "x,y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "x_reshaped = np.reshape(x, (x.shape[0], 8, 8))\n",
    "plt.imshow(x_reshaped[5, :, :])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "x_data, y_labels = load_digits(return_X_y=True)\n",
    "x_data_train, x_data_test, y_labels_train, y_labels_test = train_test_split(x_data, y_labels, train_size=0.6)\n",
    "\n",
    "logr = LogisticRegression(solver='liblinear')\n",
    "logr.fit(x_data_train, y_labels_train)\n",
    "plot_confusion_matrix(logr, x_data_test, y_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.5\n",
    "Return to Q2.4; instead of looking at all 64 pixels (dimensions), first use PCA to reduce the number pixels and then try to classify the samples. Justify your choice for the number of components (hint: this is quantifiable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x_data, y_labels = load_digits(return_X_y=True)\n",
    "x_data_train, x_data_test, y_labels_train, y_labels_test = train_test_split(x_data, y_labels, train_size=0.6)\n",
    "\n",
    "score_list = []\n",
    "for i in range(1,32):\n",
    "    pca = PCA(n_components=i)\n",
    "    pc = pca.fit_transform(x_data_train)\n",
    "    logr = LogisticRegression(solver='liblinear')\n",
    "    score_list.append(np.mean(cross_val_score(logr, pc, y_labels_train)))\n",
    "plt.plot(score_list,'.-')\n",
    "plt.xlabel('Number of PCs')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('')\n",
    "#pc_test = pca.transform(x_data_test)\n",
    "#plot_confusion_matrix(logr, pc_test, y_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance for more than ~8 components doesn't improve cross-validation results by much. Any number of components between 8-16 would work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
